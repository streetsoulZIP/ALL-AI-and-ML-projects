{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13073315,"sourceType":"datasetVersion","datasetId":8279535},{"sourceId":13073316,"sourceType":"datasetVersion","datasetId":8279536},{"sourceId":13114824,"sourceType":"datasetVersion","datasetId":8243841}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## **Этот ноутбук**: по вектора модели-исходника bge-m3 обучает модель fast-bgem3 повторят за учителем. Тут всё: от предобработки до теста."],"metadata":{"id":"7B5tDtRI3lRu"}},{"cell_type":"code","source":["\n","editor = 'kaggle'\n","base_link = '/content/' if editor=='colab' else '/kaggle/input/'"],"metadata":{"id":"plFG3BIakxAy","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T09:24:23.720365Z","iopub.execute_input":"2025-09-19T09:24:23.720824Z","iopub.status.idle":"2025-09-19T09:24:23.726835Z","shell.execute_reply.started":"2025-09-19T09:24:23.720805Z","shell.execute_reply":"2025-09-19T09:24:23.726103Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### объединяем данные"],"metadata":{"id":"M8rwU6Fx4XaD"}},{"cell_type":"code","source":["# # # # 1. Монтируем Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","\n","\n","# # 2. Копируем kaggle.json в нужную директорию\n","# !mkdir -p ~/.kaggle\n","# !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n","\n","# # 3. Устанавливаем пра3ва на файл\n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 4. Устанавливаем kaggle API (если не установлен)\n","# # !pip install -q kaggle\n","\n","# # 5. Пример скачивания датасета\n","# dataset_name = 'kehhill/part-1-vectores'\n","\n","# dataset_id = dataset_name.split('/')[-1]\n","\n","# # # 5. Скачиваем датасет\n","# !kaggle datasets download -d {dataset_name}\n","\n","# # # 6. Создаём папку и распаковываем тудк1а\n","# !mkdir -p {dataset_id}\n","\n","# !unzip -q \"{dataset_id}.zip\" -d {dataset_id}"],"metadata":{"id":"0G43G0EH0-jw"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# # # 5. Пример скачивания датасета\n","# dataset_name = 'kehhill/part-2-vectores'\n","\n","# dataset_id = dataset_name.split('/')[-1]\n","\n","# # # 5. Скачиваем датасет\n","# !kaggle datasets download -d {dataset_name}\n","\n","# # # 6. Создаём папку и распаковываем тудк1а\n","# !mkdir -p {dataset_id}\n","\n","# !unzip -q \"{dataset_id}.zip\" -d {dataset_id}"],"metadata":{"id":"UspZ1MRvhrsV"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","import os, re, glob, numpy as np, pandas as pd\n","from typing import List, Tuple, Dict\n","\n","PAIR_RE = re.compile(r\".*?part(\\d+)\\.npz$\")  # для сортировки по номеру\n","\n","def collect_shard_pairs(dir_path: str) -> List[Tuple[str, str]]:\n","    \"\"\"\n","    Находит пары (embeds_partNNN.npz, index_partNNN.csv) в папке и\n","    возвращает их отсортированными по NNN.\n","    \"\"\"\n","    npz_files = sorted(glob.glob(os.path.join(dir_path, \"*part*.npz\")))\n","    pairs = []\n","    for npz_path in npz_files:\n","        m = PAIR_RE.match(npz_path)\n","        if not m:\n","            continue\n","        n = m.group(1)\n","        idx_path = os.path.join(dir_path, f\"index_part{n}.csv\")\n","        if os.path.exists(idx_path):\n","            pairs.append((npz_path, idx_path))\n","    # отсортируем по номеру\n","    pairs.sort(key=lambda p: int(PAIR_RE.match(p[0]).group(1)))\n","    return pairs\n","\n","def collect_all_pairs(dirs: List[str]) -> List[Tuple[str, str]]:\n","    \"\"\"\n","    Конкатенирует пары от нескольких подходов (папок) в том порядке,\n","    в каком папки указаны в списке dirs.\n","    \"\"\"\n","    all_pairs = []\n","    for d in dirs:\n","        ps = collect_shard_pairs(d)\n","        if not ps:\n","            print(f\"[warn] no shard pairs in: {d}\")\n","        all_pairs.extend(ps)\n","    return all_pairs\n","\n","def summarize_pairs(pairs: List[Tuple[str, str]]) -> pd.DataFrame:\n","    rows = []\n","    for npz_path, idx_path in pairs:\n","        with np.load(npz_path, mmap_mode=\"r\") as z:\n","            n = z[\"layer_24\"].shape[0]  # любая метка, строки совпадают\n","            d = z[\"layer_24\"].shape[1]\n","        rows.append({\"npz\": os.path.basename(npz_path),\n","                     \"index\": os.path.basename(idx_path),\n","                     \"rows\": n, \"dim\": d})\n","    return pd.DataFrame(rows)\n"],"metadata":{"id":"_0XlPhegiPmd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["p1, p2 = os.path.join(base_link, \"part-1-vectores\"), os.path.join(base_link, \"part-2-vectores\")\n","\n","pairs = collect_all_pairs([p1, p2])\n","print(summarize_pairs(pairs))\n"],"metadata":{"id":"GYpfkEiWiXSh"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### создаём тестовые данные"],"metadata":{"id":"hf0ZSmcW4br8"}},{"cell_type":"code","source":["import os, glob\n","import numpy as np\n","import pandas as pd\n","\n","# где лежат пары файлов\n","DATA_DIR = p1[:]\n","\n","# выбираем какой-то .npz (первый по сортировке)\n","npz_list = sorted(glob.glob(os.path.join(DATA_DIR, \"embeds_part*.npz\")))\n","assert len(npz_list) > 0, \"Не нашёл embeds_part*.npz\"\n","npz_path = npz_list[0]\n","print(\"Using:\", npz_path)\n","\n","# пытаемся найти соответствующий index_partXXX.csv\n","part_num = os.path.splitext(os.path.basename(npz_path))[0].split(\"part\")[-1]\n","idx_path = os.path.join(DATA_DIR, f\"index_part{part_num}.csv\")\n","has_index = os.path.exists(idx_path)\n","if has_index:\n","    print(\"Index:\", idx_path)\n","else:\n","    print(\"Index CSV not found — пропущу сохранение индекса\")\n","\n","# грузим .npz (меммапом можно, но тут маленький срез — можно и нормально)\n","z = np.load(npz_path)  # dtype fp16 внутри\n","\n","# определяем сколько доступно и сколько откусить\n","N_total = z[\"layer_24\"].shape[0]\n","N_take = min(20_000, N_total)\n","print(f\"Total rows in shard: {N_total} -> taking: {N_take}\")\n","\n","# берём одинаковый срез по всем слоям\n","out = {\n","    \"layer_13\": z[\"layer_13\"][:N_take],\n","    \"layer_17\": z[\"layer_17\"][:N_take],\n","    \"layer_24\": z[\"layer_24\"][:N_take],\n","}\n","# контроль dtypes\n","for k, v in out.items():\n","    if v.dtype != np.float16:\n","        out[k] = v.astype(np.float16)\n","\n","# сохраняем тестовый набор\n","np.savez_compressed(\"test.npz\", **out)\n","print(\"Saved test.npz:\", {k: out[k].shape for k in out})\n","\n","# (опционально) сохраним такие же первые строки индекса\n","if has_index:\n","    df = pd.read_csv(idx_path)\n","    df.head(N_take).to_csv(\"test_index.csv\", index=False)\n","    print(\"Saved test_index.csv:\", len(df.head(N_take)))\n"],"metadata":{"id":"XsbjeSiNknA0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### генераторы"],"metadata":{"id":"A6tK_8ho4ePD"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import IterableDataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel\n","\n","class TeacherEmbStreamingDataset(IterableDataset):\n","    \"\"\"\n","    Стриминг по парам (npz, csv). На каждом шарде:\n","      - читаем index_partNNN.csv (колонки: idx, text)\n","      - открываем embeds_partNNN.npz (ключи: layer_13, layer_17, layer_24) — fp16\n","    Выдаёт батчи токенов + teacher-эмбеддинги.\n","    \"\"\"\n","    def __init__(self,\n","                 pairs: List[Tuple[str, str]],\n","                 tokenizer,\n","                 batch_size: int = 128,\n","                 max_len: int = 128,\n","                 text_col: str = \"text\",\n","                 device: str = \"cpu\"):\n","        self.pairs = pairs\n","        self.tok = tokenizer\n","        self.bs = batch_size\n","        self.max_len = max_len\n","        self.text_col = text_col\n","        self.device = device\n","\n","    def _yield_batches_from_shard(self, npz_path: str, idx_path: str):\n","        df = pd.read_csv(idx_path)\n","        texts = df[self.text_col].astype(str).tolist()\n","\n","        z = np.load(npz_path, mmap_mode=\"r\")\n","        z13 = z[\"layer_13\"]  # [N,D] float16\n","        z17 = z[\"layer_17\"]\n","        z24 = z[\"layer_24\"]\n","        N = len(texts)\n","\n","        for start in range(0, N, self.bs):\n","            end = min(start + self.bs, N)\n","            batch_texts = texts[start:end]\n","\n","            enc = self.tok(\n","                batch_texts,\n","                truncation=True, padding=True,\n","                max_length=self.max_len,\n","                return_tensors=\"pt\"\n","            )\n","\n","            # teacher эмбеддинги в torch (half), можно оставить на CPU — перенесёшь в train_step\n","            t13 = torch.tensor(z13[start:end], dtype=torch.float32)\n","            t17 = torch.tensor(z17[start:end], dtype=torch.float32)\n","            t24 = torch.tensor(z24[start:end], dtype=torch.float32)\n","\n","            yield {\n","                \"input_ids\": enc[\"input_ids\"],\n","                \"attention_mask\": enc[\"attention_mask\"],\n","                # xlm-roberta — без token_type_ids\n","                \"teacher\": {13: t13, 17: t17, 24: t24},\n","                \"texts\": batch_texts,  # опционально, если нужно для отладки\n","            }\n","\n","        z.close()\n","\n","    def __iter__(self):\n","        # последовательный проход по всем парам\n","        for npz_path, idx_path in self.pairs:\n","            yield from self._yield_batches_from_shard(npz_path, idx_path)\n","\n","def make_loader(pairs: List[Tuple[str, str]],\n","                tokenizer,\n","                batch_size: int = 128,\n","                max_len: int = 128,\n","                num_workers: int = 2,\n","                pin_memory: bool = True):\n","    ds = TeacherEmbStreamingDataset(\n","        pairs=pairs, tokenizer=tokenizer,\n","        batch_size=batch_size, max_len=max_len\n","    )\n","    # IterableDataset: shuffle тут не поддерживаем (нужно перешардировать заранее, если надо)\n","    return DataLoader(ds, batch_size=None, num_workers=num_workers, pin_memory=pin_memory)\n"],"metadata":{"id":"THt2ROuVifna"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","from torch.utils.data import IterableDataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel"],"metadata":{"id":"XyYw-5nCy-ku"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 2) токенайзер под student (xlm-roberta)\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/queries/bge_fast_ten_lang/bge_fast_ten_lang\", use_fast=True)\n","model = AutoModel.from_pretrained(\"/kaggle/input/queries/bge_fast_ten_lang/bge_fast_ten_lang\")\n","\n","# 3) лоадер\n","train_loader = make_loader(pairs, tokenizer, batch_size=128, max_len=42)"],"metadata":{"id":"A1MQc-gni2nN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","\n","class TestDataset(Dataset):\n","    def __init__(self, npz_path: str, csv_path: str, tokenizer, max_len=128):\n","        self.data = np.load(npz_path)\n","        self.texts = pd.read_csv(csv_path)[\"text\"].astype(str).tolist()\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        enc = self.tokenizer(\n","            text,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        # вытаскиваем teacher эмбеддинги\n","        teacher = {\n","            13: torch.tensor(self.data[\"layer_13\"][idx], dtype=torch.float16),\n","            17: torch.tensor(self.data[\"layer_17\"][idx], dtype=torch.float16),\n","            24: torch.tensor(self.data[\"layer_24\"][idx], dtype=torch.float16),\n","        }\n","        return {\n","            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n","            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n","            \"teacher\": teacher,\n","            \"text\": text\n","        }\n","\n","# --- использование ---\n","\n","\n","test_ds = TestDataset(\"test.npz\", \"test_index.csv\", tokenizer, max_len=42)\n","test_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n","\n","# пример: берём один батч\n","for batch in test_loader:\n","    print(batch[\"input_ids\"].shape)   # [B, L]\n","    print(batch[\"teacher\"][24].shape)  # [B, D]\n","    break\n"],"metadata":{"id":"8YZJR7OGmvUT"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### мультичекпоинт лосс"],"metadata":{"id":"ngLsg2IJ4hNe"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def _mean_pool(last_hidden_state, attention_mask):\n","    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)  # [B,T,1]\n","    summed = (last_hidden_state * mask).sum(dim=1)                  # [B,D]\n","    denom = mask.sum(dim=1).clamp_min(1e-6)                         # [B,1]\n","    return summed / denom\n","\n","class MultiCheckpointLoss(nn.Module):\n","    def __init__(self, student_to_teacher, weights=None):\n","        \"\"\"\n","        student_to_teacher: dict {student_layer_idx: teacher_layer_idx}\n","        weights: dict {student_layer_idx: weight}, если None -> все = 1.0\n","        \"\"\"\n","        super().__init__()\n","        self.student_to_teacher = student_to_teacher\n","        self.weights = weights or {Ls: 1.0 for Ls in student_to_teacher}\n","        self.cos = nn.CosineEmbeddingLoss()\n","\n","    def forward(self, s_hidden, t_hidden, attention_mask):\n","        \"\"\"\n","        s_hidden: dict {layer_idx: [B,T,D]}  (student hidden_states)\n","        t_hidden: dict {layer_idx: [B,D]}    (teacher pooled embeddings)\n","        attention_mask: [B,T]\n","        \"\"\"\n","        total_loss = 0.0\n","        B = attention_mask.size(0)\n","        target = torch.ones(B, device=attention_mask.device)\n","\n","        for Ls, Lt in self.student_to_teacher.items():\n","            s = _mean_pool(s_hidden[Ls], attention_mask)  # [B,D]\n","            t = t_hidden[Lt].detach()                     # [B,D]\n","            total_loss += self.weights.get(Ls, 1.0) * self.cos(s, t, target)\n","\n","        return total_loss\n"],"metadata":{"id":"ddeHuT4gyIn7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### утилиты"],"metadata":{"id":"Ghtqy70k4kV0"}},{"cell_type":"code","source":["def build_layer_param_map(model):\n","    \"\"\"\n","    Делает словарь {layer_idx: [имена параметров]} для encoder.layer.*,\n","    плюс \"others\" для всего остального.\n","    \"\"\"\n","    layer_map = {}\n","    total = len(model.encoder.layer)\n","\n","    for n, p in model.named_parameters():\n","        matched = False\n","        for i in range(total):\n","            if f\"encoder.layer.{i}.\" in n:\n","                idx = i + 1  # 1-based индекс\n","                layer_map.setdefault(idx, []).append(n)\n","                matched = True\n","                break\n","        if not matched:\n","            layer_map.setdefault(\"others\", []).append(n)\n","\n","    return layer_map\n","\n","layer_map = build_layer_param_map(model)"],"metadata":{"id":"pj_wffQD9xSK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def set_layer_lrs(model, assignments, base_opt=torch.optim.AdamW, layer_map=None, **opt_kwargs):\n","    \"\"\"\n","    Если optimizer=None -> создаём новый AdamW с группами под assignments.\n","    Если optimizer передан -> пересоздаём его param_groups (без потери state).\n","    \"\"\"\n","    assert layer_map is not None, \"Нужен layer_map!\"\n","\n","    # проверяем корректность assignments\n","    all_parts = list(layer_map.keys())\n","    model_part_assign = [j for i in assignments for j in i[0]]\n","    missed_layers = [i for i in all_parts if i not in model_part_assign]\n","    bad_layers = [i for i in model_part_assign if i not in all_parts]\n","    assert missed_layers==[], f\"Assignment should contain all layers that model has! You missed: {missed_layers}\"\n","    assert bad_layers==[], f\"You point layers that model hasn't: {bad_layers}\"\n","\n","    # строим группы\n","    param_groups = []\n","    for indices, val in assignments:\n","        for idx in indices:\n","            names = layer_map[idx]\n","            params = [p for n, p in model.named_parameters() if n in names]\n","            group = {\"params\": params, \"name\": f\"layer_{idx}\"}\n","            if val == \"freeze\":\n","                for p in params:\n","                    p.requires_grad = False\n","                group[\"lr\"] = 0.0\n","                group[\"frozen\"] = True\n","            else:\n","                for p in params:\n","                    p.requires_grad = True\n","                group[\"lr\"] = float(val)\n","                group[\"frozen\"] = False\n","            param_groups.append(group)\n","\n","\n","    optimizer = base_opt(param_groups, **opt_kwargs)\n","\n","    return optimizer\n"],"metadata":{"id":"q_GwgBl_90Dj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def scale_unfrozen_lrs(optimizer, factor):\n","    \"\"\"\n","    action = 'increase' или 'decrease'\n","    factor = число, например 2.0\n","    \"\"\"\n","    for g in optimizer.param_groups:\n","        if not g.get(\"frozen\", False):\n","            g[\"lr\"] *= factor\n"],"metadata":{"id":"WPvB30ui90Ns"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def wurm_up_sheduler(optimizer, cur_step, wurm_up_steps=1000):\n","  if cur_step<=wurm_up_steps:\n","      scale_unfrozen_lrs(optimizer, cur_step/wurm_up_steps)"],"metadata":{"id":"m8q2yfla5bhA"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model.to('cuda')\n","print()"],"metadata":{"id":"8drzo5WUdzbv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.nn.utils import clip_grad_norm_\n","\n","# --- готовим модель, оптимайзер ---\n","device = \"cuda\"\n","model.to(device)\n","\n","# оптимайзер\n","from torch.optim import AdamW\n","# [1,2,5,9,13,17,20,23,24]\n","# [1,2,3,4,5,6,7,8,9]\n","\n","assign_1 = [(['others', 1,2], 'freeze'),([3,4,5,6], 1e-4),([7,8,9], 2e-4)]\n","assign_2 = [(['others', 1,2], 'freeze'),([3,4,5,6], 2e-5),([7,8,9], 4e-5)]\n","optimizer = set_layer_lrs(model, assign_1, base_opt=torch.optim.AdamW, layer_map=layer_map)\n","\n","# grad scaler для FP16\n","scaler = GradScaler()\n","\n","checnkpoint_layers = [4, 6, 9]\n","\n","\n","# лосс (по новым индексам)\n","student_to_teacher = {4: 13, 6: 17, 9: 24}  # пример маппинга\n","\n","loss_fn = MultiCheckpointLoss(\n","    student_to_teacher=student_to_teacher,\n","    weights={4:0.2, 6:0.2, 9:1.0}  # кастомные веса\n",")\n","\n","step_start_count = 0\n","phase = 1\n","val_freq = 2000 # in steps\n","# --- тренинг ---\n","num_epochs = 2\n","cnt_decrease_lr = 0\n","stop_training = False\n","base_patience = 1\n","patience = base_patience  # works only after phase 2\n","val_loss_dynamic = [1000]\n","count_running_savers_phase_1 = 0\n","step = 0\n","for epoch in range(num_epochs):\n","\n","    running_loss = 0.0\n","\n","\n","    if stop_training: break\n","    for batch in train_loader:\n","        if stop_training: break\n","\n","        step+=1\n","\n","        ids = batch[\"input_ids\"].to(device)\n","        attn = batch[\"attention_mask\"].to(device)\n","        teacher_hiddens = {L: batch[\"teacher\"][L].to(device) for L in batch[\"teacher\"]}\n","\n","        model.zero_grad(set_to_none=True)\n","\n","\n","        with autocast(enabled=True):\n","            s_out = model(\n","                input_ids=ids,\n","                attention_mask=attn,\n","                output_hidden_states=True,\n","                return_dict=True,\n","            )\n","            # забираем student эмбеддинги\n","            student_hiddens = {L: s_out.hidden_states[L] for L in checnkpoint_layers}\n","\n","            # teacher храним/кастуем в float32 → лосс будет считаться стабильно\n","            teacher_hiddens = {L: teacher_hiddens[L].float() for L in teacher_hiddens}\n","\n","            loss = loss_fn(student_hiddens, teacher_hiddens, attn)\n","\n","        scaler.scale(loss).backward()\n","\n","        # grad clipping (после unscale)\n","        scaler.unscale_(optimizer)\n","        clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        # шаг оптимизатора\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","\n","\n","        running_loss += loss.item()\n","\n","\n","        if phase==2:\n","          wurm_up_sheduler(optimizer, step-step_start_count, wurm_up_steps=800)\n","\n","        if step % 400 == 0:\n","            print(f\"epoch {epoch} step {step} | loss {running_loss/400:.4f}\")\n","\n","            count_running_savers_phase_1+=1\n","            if phase==1 and (running_loss < 0.22 or epoch != 0):\n","                print('Loss reach phase 1 goal, it is turn for phase 2!')\n","                optimizer = set_layer_lrs(model, assign_2, base_opt=torch.optim.AdamW, layer_map=layer_map)\n","                step_start_count = step\n","                phase = 2\n","            if phase==1 and count_running_savers_phase_1==5:\n","                val_loss_dynamic.append(running_loss)\n","            running_loss = 0.0\n","\n","        if phase==2 and (step-step_start_count)%val_freq==0:\n","          model.eval()\n","          val_loss = 0.0\n","          with torch.inference_mode():\n","              for batch in test_loader:\n","                  ids = batch[\"input_ids\"].to(device)\n","                  attn = batch[\"attention_mask\"].to(device)\n","                  teacher_hiddens = {L: batch[\"teacher\"][L].to(device) for L in batch[\"teacher\"]}\n","\n","                  with autocast(enabled=True):\n","                      s_out = model(input_ids=ids, attention_mask=attn, output_hidden_states=True, return_dict=True)\n","\n","                      student_hiddens = {L: s_out.hidden_states[L] for L in checnkpoint_layers}\n","                      loss = loss_fn(student_hiddens, teacher_hiddens, attn)\n","                  val_loss += loss.item()\n","          val_loss /= len(test_loader)\n","\n","          val_loss_dynamic.append(val_loss)\n","          print(f\"epoch {epoch} | val_loss={val_loss:.4f}\")\n","\n","          if min(val_loss_dynamic[:-1])*0.98<=val_loss:\n","              patience-=1\n","              cnt_decrease_lr += 1\n","              scale_unfrozen_lrs(optimizer, 1/2)\n","              if patience==0:\n","                print(\"Traing stopped on epoch {epoch+1}, step {step} due to no progress!\")\n","                stop_training = True\n","              if cnt_decrease_lr==2:\n","                print(\"Traing stopped on epoch {epoch+1}, step {step} due to limit for decreasing lr!\")\n","                stop_training = True\n","          if min(val_loss_dynamic[:-1])*0.98>val_loss:\n","            print('Save new best model with val loss ', val_loss)\n","            patience = base_patience\n","            save_small = 'bge_fast_ten_lang_pretrained'\n","            os.makedirs(save_small, exist_ok=True)\n","            model.save_pretrained(save_small)\n","          model.train()\n","\n","    # валидация после эпохи\n","\n","\n","\n"],"metadata":{"id":"hINsO6rt40mg"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(val_loss_dynamic)"],"metadata":{"id":"J06jFjAjKR0_"},"outputs":[],"execution_count":null}]}