{"cells":[{"cell_type":"markdown","source":["## **Этот ноутбук**: используя запросы пользователей (синтетические + из других датасетов), векторизирует их с помощью bge-m3 и сохраняет."],"metadata":{"id":"9xEYKOiX4CIq"},"id":"9xEYKOiX4CIq"},{"cell_type":"code","execution_count":null,"id":"bfb91ee0","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-09-16T03:47:41.685314Z","iopub.status.busy":"2025-09-16T03:47:41.685109Z","iopub.status.idle":"2025-09-16T04:12:17.125195Z","shell.execute_reply":"2025-09-16T04:12:17.124431Z"},"papermill":{"duration":1475.445235,"end_time":"2025-09-16T04:12:17.127728","exception":false,"start_time":"2025-09-16T03:47:41.682493","status":"completed"},"tags":[],"id":"bfb91ee0","outputId":"0c9b9f14-5cf6-4d58-cc75-daa3e2b98a1a","colab":{"referenced_widgets":["ae877e6b398d4856bc8771b6ed160a4c","7ecc9a4f7ccb4cd082bb1177c413607e","4343740c66d84a4f8f8ee251b4c50ee7","5212784d60d14832a407f67e291a7c4d","ab844bf4e08b4c779e4fbba8a6b3d61c","54eedae1356e4b0b8f3698a8c899d543","5ecd21ecfd654df3b0504a888854a098"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae877e6b398d4856bc8771b6ed160a4c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ecc9a4f7ccb4cd082bb1177c413607e","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4343740c66d84a4f8f8ee251b4c50ee7","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5212784d60d14832a407f67e291a7c4d","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab844bf4e08b4c779e4fbba8a6b3d61c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2025-09-16 03:48:15.697186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757994495.895525      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757994495.951237      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54eedae1356e4b0b8f3698a8c899d543","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ecd21ecfd654df3b0504a888854a098","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saved part 1 | rows=272384\n","Saved part 2 | rows=272384\n","Saved part 3 | rows=139662\n"]}],"source":["# -*- coding: utf-8 -*-\n","import os, math, torch, pandas as pd, numpy as np\n","from typing import List, Dict, Any\n","from transformers import AutoTokenizer, AutoModel\n","\n","# ---- конфиг ----\n","MODEL_NAME = \"BAAI/bge-m3\"\n","TEXT_COL = \"text\"\n","BATCH_SIZE = 2048\n","MAX_LEN = 42\n","CHECKPOINT_LAYERS = [13, 17, 24]\n","\n","# ---- данные ----\n","df = pd.read_parquet(\"/kaggle/input/queries/transef_lerning_merged_10_langueges.parquet\")\n","texts = []\n","for i in range(len(df)):\n","    for col in df.columns:\n","        texts.append(df[col].iloc[i])\n","\n","# ---- cuda тюн ----\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,expandable_segments:True,garbage_collection_threshold:0.6\"\n","torch.backends.cuda.matmul.allow_tf32 = True\n","torch.backends.cuda.enable_flash_sdp(True)\n","torch.backends.cuda.enable_mem_efficient_sdp(True)\n","torch.backends.cuda.enable_math_sdp(False)\n","\n","# ---- pooling ----\n","def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n","    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n","    summed = (last_hidden_state * mask).sum(dim=1)\n","    denom = mask.sum(dim=1).clamp_min(1e-6)\n","    return summed / denom\n","\n","# ---- модель ----\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","model = AutoModel.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","model.eval()\n","\n","@torch.inference_mode()\n","def encode_checkpoints(batch_texts: List[str]) -> Dict[int, np.ndarray]:\n","    enc = tokenizer(batch_texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n","    first_device = next(iter(model.parameters())).device\n","    enc = {k: v.to(first_device) for k, v in enc.items()}\n","    with torch.autocast(\"cuda\", dtype=torch.float16):\n","        out = model(**enc, output_hidden_states=True, return_dict=True)\n","        hs = out.hidden_states\n","    attn = enc[\"attention_mask\"]\n","\n","    pooled = {}\n","    for L in CHECKPOINT_LAYERS:\n","        h = mean_pool(hs[L], attn)\n","        h = torch.nn.functional.normalize(h, p=2, dim=-1)\n","        pooled[L] = h.half().cpu().numpy()\n","    return pooled\n","\n","# ---- батчинг и сохранение ----\n","num_batches = math.ceil(len(texts) / BATCH_SIZE)\n","\n","global_part_num = 2\n","global_part_count = 2\n","texts = texts[len(texts)*(global_part_num-1)//global_part_count : len(texts)*global_part_num//global_part_count]\n","\n","split_on = 5\n","save_every = max(1, num_batches // split_on)\n","\n","file_part = 1\n","buf_layers = {L: [] for L in CHECKPOINT_LAYERS}\n","buf_index = []\n","\n","for bi in range(num_batches):\n","    sl = slice(bi * BATCH_SIZE, (bi + 1) * BATCH_SIZE)\n","    batch = texts[sl]\n","    if not batch:\n","        continue\n","\n","    pooled_dict = encode_checkpoints(batch)\n","    B = pooled_dict[CHECKPOINT_LAYERS[0]].shape[0]\n","\n","    # накапливаем\n","    for L in CHECKPOINT_LAYERS:\n","        buf_layers[L].append(pooled_dict[L])\n","    for i in range(B):\n","        buf_index.append({\"idx\": bi * BATCH_SIZE + i, TEXT_COL: batch[i]})\n","\n","    # сохраняем кусок\n","    if (bi + 1) % save_every == 0:\n","        if buf_index:\n","            arrs = {f\"layer_{L}\": np.concatenate(buf_layers[L], axis=0).astype(np.float16) for L in CHECKPOINT_LAYERS}\n","            np.savez_compressed(f\"embeds_part{file_part:03d}.npz\", **arrs)\n","            pd.DataFrame(buf_index).to_csv(f\"index_part{file_part:03d}.csv\", index=False)\n","            print(f\"Saved part {file_part} | rows={len(buf_index)}\")\n","            file_part += 1\n","            buf_layers = {L: [] for L in CHECKPOINT_LAYERS}\n","            buf_index = []\n","\n","# хвост\n","if buf_index:\n","    arrs = {f\"layer_{L}\": np.concatenate(buf_layers[L], axis=0).astype(np.float16) for L in CHECKPOINT_LAYERS}\n","    np.savez_compressed(f\"embeds_part{file_part:03d}.npz\", **arrs)\n","    pd.DataFrame(buf_index).to_csv(f\"index_part{file_part:03d}.csv\", index=False)\n","    print(f\"Saved part {file_part} | rows={len(buf_index)}\")\n"]},{"cell_type":"code","execution_count":null,"id":"2661e9cd","metadata":{"papermill":{"duration":0.001623,"end_time":"2025-09-16T04:12:17.131462","exception":false,"start_time":"2025-09-16T04:12:17.129839","status":"completed"},"tags":[],"id":"2661e9cd"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":8243841,"sourceId":13033858,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":1482.881278,"end_time":"2025-09-16T04:12:20.384232","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-16T03:47:37.502954","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}