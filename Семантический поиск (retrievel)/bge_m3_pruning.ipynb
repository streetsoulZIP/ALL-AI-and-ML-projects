{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1WfvnNGO-cVWBcvGnqELiAZkcLwTEWAg8","authorship_tag":"ABX9TyMbAahKzy899xSQw1RtzcKP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Этот ноутбук**: токенизирует текста и смотрит полезные токены, обрезает словарь, эмбеддинги модели, а так же оставляет в модели только те слои, что было решено оставить после анализа и сохраняет обновлённую модель."],"metadata":{"id":"pPbPyFj606kZ"}},{"cell_type":"markdown","source":["# Прунинг словаря (10 языков)"],"metadata":{"id":"YCjPTHNzrWSp"}},{"cell_type":"code","source":["# # # 1. Монтируем Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","\n","# 2. Копируем kaggle.json в нужную директорию\n","!mkdir -p ~/.kaggle\n","!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n","\n","# 3. Устанавливаем пра3ва на файл\n","!chmod 600 ~/.kaggle/kaggle.json\n","# 4. Устанавливаем kaggle API (если не установлен)\n","# !pip install -q kaggle\n","\n","# 5. Пример скачивания датасета\n","dataset_name = 'kehhill/queries'\n","\n","dataset_id = dataset_name.split('/')[-1]\n","\n","# # 5. Скачиваем датасет\n","!kaggle datasets download -d {dataset_name}\n","\n","# # 6. Создаём папку и распаковываем тудк1а\n","!mkdir -p {dataset_id}\n","\n","!unzip -q \"{dataset_id}.zip\" -d {dataset_id}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ob2vJRv5zKoj","executionInfo":{"status":"ok","timestamp":1758255860437,"user_tz":-180,"elapsed":66276,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"e1c32ac6-1c87-41f9-a585-3f43bb3309b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Dataset URL: https://www.kaggle.com/datasets/kehhill/queries\n","License(s): unknown\n","Downloading queries.zip to /content\n"," 98% 684M/702M [00:03<00:00, 135MB/s]\n","100% 702M/702M [00:03<00:00, 193MB/s]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","tf = pd.read_parquet(\"/content/queries/transef_lerning_merged_10_langueges.parquet\")\n","fine_tine = pd.read_parquet(\"/content/queries/fine_tune_10_langueges.parquet\")"],"metadata":{"id":"lZ9mPBElz71F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extended_texts = []\n","\n","for i in range(len(tf)):\n","    for col in tf.columns:\n","        extended_texts.append(tf[col].iloc[i])\n","\n","for i in range(len(fine_tine)):\n","    for col in fine_tine.columns:\n","        extended_texts.append(fine_tine[col].iloc[i])"],"metadata":{"id":"rqxeYkVC0LJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install wordfreq"],"metadata":{"id":"uHuKypf6JhFS","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.150773Z","iopub.execute_input":"2025-08-27T10:13:00.150972Z","iopub.status.idle":"2025-08-27T10:13:00.165859Z","shell.execute_reply.started":"2025-08-27T10:13:00.150957Z","shell.execute_reply":"2025-08-27T10:13:00.165342Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757997652151,"user_tz":-180,"elapsed":9361,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"caf78d06-6016-42fd-dfec-573dee606775"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wordfreq\n","  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\n","Collecting ftfy>=6.1 (from wordfreq)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (3.5.0)\n","Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\n","  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (1.1.1)\n","Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (2024.11.6)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1->wordfreq) (0.2.13)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes>=3.0->wordfreq) (1.3.0)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes>=3.0->wordfreq) (1.3.1)\n","Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n","Installing collected packages: locate, ftfy, wordfreq\n","Successfully installed ftfy-6.3.1 locate-1.1.1 wordfreq-3.1.1\n"]}],"execution_count":null},{"cell_type":"code","source":["from wordfreq import top_n_list\n","import pandas as pd\n","import random\n","import string\n","\n","# ===== Настройки =====\n","languages = [\"en\", \"es\", \"de\", \"fr\", \"pt\", \"ru\", \"it\", \"nl\", \"pl\", \"tr\"]\n","top_n = 300_000\n","words_per_sentence = 20\n","\n","# ===== Сбор слов =====\n","all_words = []\n","for lang in languages:\n","    words = top_n_list(lang, top_n)\n","    all_words.extend(words)\n","\n","# ===== Перемешиваем и формируем \"предложения\" =====\n","random.shuffle(all_words)\n","\n","sentences = []\n","for i in range(0, len(all_words), words_per_sentence):\n","    chunk = all_words[i:i+words_per_sentence]\n","    if len(chunk) == words_per_sentence:\n","        sentences.append(\" \" + \" \".join(chunk) + \" \")\n","\n","# ===== Добавляем \"спец предложения\" с пунктуацией =====\n","special_chars = list(string.punctuation) + [\"«\", \"»\", \"—\", \"…\", \"“\", \"”\", \"„\", \"’\", \"‘\"]\n","special_sentence = \" \" + \" \".join(special_chars) + \" \"\n","sentences.append(special_sentence)\n","\n","# ===== Сохраняем в Parquet =====\n","df = pd.DataFrame({\"text\": sentences+extended_texts})\n","output_file = \"multilang_vocab_dataset.parquet\"\n","df.to_parquet(output_file, index=False)\n","\n","# ===== Вывод информации =====\n","(df.shape, output_file)\n"],"metadata":{"id":"sC56e1q-Jfj6","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.166519Z","iopub.execute_input":"2025-08-27T10:13:00.166782Z","iopub.status.idle":"2025-08-27T10:13:00.182725Z","shell.execute_reply.started":"2025-08-27T10:13:00.166761Z","shell.execute_reply":"2025-08-27T10:13:00.182218Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757997689963,"user_tz":-180,"elapsed":4930,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"f5dce2a6-cd86-4016-b02b-fabcbfcff1ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1725396, 1), 'multilang_vocab_dataset.parquet')"]},"metadata":{},"execution_count":8}],"execution_count":null},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","from tqdm import tqdm\n","import json\n","import os\n","\n","# ==== Настройки ====\n","MODEL_NAME = \"BAAI/bge-m3\"\n","INPUT_PARQUET = \"multilang_vocab_dataset.parquet\"  # твой датасет\n","SAVE_PATH = \"bge-m3-reduced\"\n","\n","# ==== Загрузка токенайзера и модели ====\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# ==== 1. Сбор used_token_ids ====\n","df = pd.read_parquet(INPUT_PARQUET)\n","\n","unique_token_ids = set()\n","for text in tqdm(df[\"text\"], desc=\"Tokenizing\", ncols=100, dynamic_ncols=True, leave=True):\n","    token_ids = tokenizer.encode(text, add_special_tokens=False)\n","    unique_token_ids.update(token_ids)\n","\n","with open(f\"unique_tokens_ids.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for tid in sorted(unique_token_ids):\n","        f.write(f\"{tid}\\n\")\n","\n"],"metadata":{"id":"2MlDTCsefI1h","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.183447Z","iopub.execute_input":"2025-08-27T10:13:00.183681Z","iopub.status.idle":"2025-08-27T10:13:00.205068Z","shell.execute_reply.started":"2025-08-27T10:13:00.183659Z","shell.execute_reply":"2025-08-27T10:13:00.204466Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757998334459,"user_tz":-180,"elapsed":368177,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"8bc9c80e-9bed-4920-de45-def38bda3aac"},"outputs":[{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 1725396/1725396 [05:53<00:00, 4886.42it/s]\n"]}],"execution_count":null},{"cell_type":"markdown","source":["# Прунинг модели\n"],"metadata":{"id":"DSOF-WUsS7PZ"}},{"cell_type":"code","source":["import os\n","import json\n","from transformers import AutoTokenizer, AutoModel\n","\n","# === Настройки ===\n","MODEL_NAME = \"BAAI/bge-m3\"\n","USED_TOKEN_IDS_PATH = \"/content/unique_tokens_ids.txt\"\n","\n","\n","# === Загрузка токенизатора и ID из датасета ===\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","# загружаем модель\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","with open(USED_TOKEN_IDS_PATH, \"r\", encoding=\"utf-8\") as f:\n","    unique_token_ids = sorted([\n","        int(line.strip()) for line in f\n","        if line.strip().isdigit()\n","    ])\n","\n","old_vocab = tokenizer.get_vocab()\n","core_spec = ['<s>', '</s>', '<unk>', '<pad>']\n","id_spec_tok = {t: old_vocab[t] for t in tokenizer.all_special_tokens if t in core_spec}\n","additional = [old_vocab[t] for t in tokenizer.all_special_tokens if t not in core_spec]\n","\n","\n","all_ids = sorted([i for i in list(set(unique_token_ids)) if i not in id_spec_tok.values()]+additional)\n","start_id = 4\n","switch_vocab = {k: v for v, k in old_vocab.items()}\n","id_to_token = {switch_vocab[id]: i+start_id for i, id in zip(range(len(all_ids)), all_ids)}\n","filtered_vocab = {k: v for k, v in list(id_spec_tok.items())+list(id_to_token.items())}\n"],"metadata":{"id":"RJLIrt5Yim7v","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.206908Z","iopub.execute_input":"2025-08-27T10:13:00.207496Z","iopub.status.idle":"2025-08-27T10:13:00.224539Z","shell.execute_reply.started":"2025-08-27T10:13:00.207479Z","shell.execute_reply":"2025-08-27T10:13:00.223834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from transformers import AutoTokenizer, PreTrainedTokenizerFast\n","from tokenizers import Tokenizer\n","from tokenizers.models import Unigram"],"metadata":{"id":"99LrceRaFN3I","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.225145Z","iopub.execute_input":"2025-08-27T10:13:00.225317Z","iopub.status.idle":"2025-08-27T10:13:00.243172Z","shell.execute_reply.started":"2025-08-27T10:13:00.225303Z","shell.execute_reply":"2025-08-27T10:13:00.242512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["backend_vocab_list = sorted(filtered_vocab.items(), key=lambda x: x[1])  # сортируем по ID\n","backend_model = Unigram(vocab=backend_vocab_list, unk_id=filtered_vocab.get(tokenizer.unk_token, 0))\n","backend_tokenizer = Tokenizer(backend_model)\n","\n","# 4. Копируем нормализаторы, препроцессоры и постпроцессоры из старого токенайзера\n","backend_tokenizer.normalizer = tokenizer.backend_tokenizer.normalizer\n","backend_tokenizer.pre_tokenizer = tokenizer.backend_tokenizer.pre_tokenizer\n","backend_tokenizer.decoder = tokenizer.backend_tokenizer.decoder\n","backend_tokenizer.post_processor = tokenizer.backend_tokenizer.post_processor\n","\n","# 5. Создаём новый PreTrainedTokenizerFast\n","new_tokenizer = PreTrainedTokenizerFast(\n","    tokenizer_object=backend_tokenizer,\n","    bos_token=tokenizer.bos_token,\n","    eos_token=tokenizer.eos_token,\n","    unk_token=tokenizer.unk_token,\n","    pad_token=tokenizer.pad_token,\n","    cls_token=tokenizer.cls_token,\n","    sep_token=tokenizer.sep_token,\n","    mask_token=tokenizer.mask_token\n",")\n","\n","# 6. Проверяем\n","print(new_tokenizer.vocab_size)\n","print(new_tokenizer.tokenize(\"Привет мир\"))\n","print(new_tokenizer.encode(\"Привет мир\"))\n"],"metadata":{"id":"WMN6HareGS2g","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.244009Z","iopub.execute_input":"2025-08-27T10:13:00.244226Z","iopub.status.idle":"2025-08-27T10:13:00.258324Z","shell.execute_reply.started":"2025-08-27T10:13:00.244205Z","shell.execute_reply":"2025-08-27T10:13:00.257588Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758271509826,"user_tz":-180,"elapsed":1426,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"b1681cc7-6d4c-44ee-f7b5-278eaf32eea4"},"outputs":[{"output_type":"stream","name":"stdout","text":["88795\n","['▁Пр', 'и', 'вет', '▁м', 'ир']\n","[0, 25717, 86, 10903, 2380, 12472, 2]\n"]}],"execution_count":null},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModel\n","\n","\n","# 2. Получаем старые эмбеддинги\n","old_emb = model.get_input_embeddings().weight.data.clone()\n","\n","# 3. Создаём новый тензор эмбеддингов\n","new_vocab_size = len(filtered_vocab)\n","embedding_dim = old_emb.size(1)\n","new_emb = torch.zeros((new_vocab_size, embedding_dim), dtype=old_emb.dtype)\n","\n","# 4. Переносим веса для токенов, которые остались\n","for token, new_id in filtered_vocab.items():\n","    old_id = old_vocab[token]\n","    new_emb[new_id] = old_emb[old_id]\n","\n"],"metadata":{"id":"y8DlfHcnQ1EF","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.259064Z","iopub.execute_input":"2025-08-27T10:13:00.259224Z","iopub.status.idle":"2025-08-27T10:13:00.279503Z","shell.execute_reply.started":"2025-08-27T10:13:00.259211Z","shell.execute_reply":"2025-08-27T10:13:00.278972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 5. Обновляем эмбеддинги модели\n","model.resize_token_embeddings(new_vocab_size)  # создаём новый слой нужного размера\n","model.get_input_embeddings().weight.data = new_emb\n","# 6. Обновляем конфиг\n","model.config.vocab_size = new_vocab_size"],"metadata":{"id":"gOjXWijFQ_j5","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.2803Z","iopub.execute_input":"2025-08-27T10:13:00.280493Z","iopub.status.idle":"2025-08-27T10:13:00.295176Z","shell.execute_reply.started":"2025-08-27T10:13:00.280477Z","shell.execute_reply":"2025-08-27T10:13:00.2947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# tokenizer.save_pretrained(small_SAVE_PATH)\n","import torch.nn as nn\n","\n","cfg = model.config\n","\n","print('ДО')\n","print(f\"layers={cfg.num_hidden_layers}, ffn_dim={cfg.intermediate_size}, max_pos={cfg.max_position_embeddings}\")\n","print(f\"Параметров: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n","old_param = sum(p.numel() for p in model.parameters())\n","print('-'*20)\n","print()\n","\n","\n","\n","\n","\n","\n","# === Обновление конфига ===\n","\n","import torch\n","from transformers import AutoModel, AutoTokenizer\n","\n","MODEL_NAME = \"BAAI/bge-m3\"\n","KEEP_LAYERS = [1,2,5,9,13,17,20, 23,24]\n","\n","# урезаем encoder\n","orig_layers = model.encoder.layer\n","new_layers = torch.nn.ModuleList([orig_layers[i-1] for i in KEEP_LAYERS])\n","model.encoder.layer = new_layers\n","\n","# обновляем конфиг\n","model.config.num_hidden_layers = len(KEEP_LAYERS)\n","\n","print(f\"Оставлено {len(KEEP_LAYERS)} слоёв: {KEEP_LAYERS}\")\n","\n","print('ПОСЛЕ')\n","print(f\"layers={cfg.num_hidden_layers}, ffn_dim={cfg.intermediate_size}, max_pos={cfg.max_position_embeddings}\")\n","print(f\"Параметров: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n","new_param = sum(p.numel() for p in model.parameters())\n","\n","print('\\nИтог:')\n","print(f\"Количество параметром уменьшилось на {round(100*(1-new_param/old_param), 2)} %\")\n"],"metadata":{"id":"7EuSDxwWSrB6","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.321687Z","iopub.execute_input":"2025-08-27T10:13:00.321926Z","iopub.status.idle":"2025-08-27T10:13:00.341764Z","shell.execute_reply.started":"2025-08-27T10:13:00.321911Z","shell.execute_reply":"2025-08-27T10:13:00.341257Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758271516693,"user_tz":-180,"elapsed":6,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"75b11772-301e-45ed-e0b3-cba4611c4d8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ДО\n","layers=24, ffn_dim=4096, max_pos=8194\n","Параметров: 402.7M\n","--------------------\n","\n","Оставлено 9 слоёв: [1, 2, 5, 9, 13, 17, 20, 23, 24]\n","ПОСЛЕ\n","layers=9, ffn_dim=4096, max_pos=8194\n","Параметров: 213.7M\n","\n","Итог:\n","Количество параметром уменьшилось на 46.92 %\n"]}],"execution_count":null},{"cell_type":"markdown","source":["## Сохраняем модель"],"metadata":{"id":"qIksKld41gMq"}},{"cell_type":"code","source":["save_small = '/content/drive/MyDrive/bge_fast_ten_lang'\n","os.makedirs(save_small, exist_ok=True)\n","model.save_pretrained(save_small)\n","new_tokenizer.save_pretrained(save_small)"],"metadata":{"id":"D-CVMjgInxJ4","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T10:13:00.342362Z","iopub.execute_input":"2025-08-27T10:13:00.342616Z","iopub.status.idle":"2025-08-27T10:13:00.367478Z","shell.execute_reply.started":"2025-08-27T10:13:00.342601Z","shell.execute_reply":"2025-08-27T10:13:00.366755Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758271531239,"user_tz":-180,"elapsed":14544,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"ac2b9e4b-5125-4824-dc86-32cd3d46fb69"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/bge_fast_ten_lang/tokenizer_config.json',\n"," '/content/drive/MyDrive/bge_fast_ten_lang/special_tokens_map.json',\n"," '/content/drive/MyDrive/bge_fast_ten_lang/tokenizer.json')"]},"metadata":{},"execution_count":23}],"execution_count":null},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/bge_fast_ten_lang')\n","# загружаем модель\n","model = AutoModel.from_pretrained('/content/drive/MyDrive/bge_fast_ten_lang')"],"metadata":{"id":"k13mlyY53WSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(p.numel() for p in model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcIXj8cH6odi","executionInfo":{"status":"ok","timestamp":1758271532086,"user_tz":-180,"elapsed":6,"user":{"displayName":"KEHHILL KEHHILL","userId":"16631532590014918715"}},"outputId":"9f726945-d089-468e-f2f3-a1f51cb2f821"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["213735424"]},"metadata":{},"execution_count":25}]}]}