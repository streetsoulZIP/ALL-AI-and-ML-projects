{"cells":[{"cell_type":"markdown","source":["## **Этот ноутбук**: использует mistral-instruct-7b, генерирует исходя из описаний фильмов планы-описания по 11 аспектам: от жанра до настроения финала.\n","\n","Заметка: модель справилась отлично, но не все описания содержат, например, тон финала и так далее. Однако из 11 аспектов более, чем у 75% ответов модели 8 и более аспектов были заполнены (8 заполненых аспектах считаем релевантными, почему: см. ноутбук generating-queries-with-qwen)."],"metadata":{"id":"yrI3IWZB8fT7"},"id":"yrI3IWZB8fT7"},{"cell_type":"code","execution_count":null,"id":"f77202c3","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:27:57.135682Z","iopub.status.busy":"2025-09-05T14:27:57.135474Z","iopub.status.idle":"2025-09-05T14:27:57.142934Z","shell.execute_reply":"2025-09-05T14:27:57.142277Z"},"id":"f77202c3","papermill":{"duration":0.018369,"end_time":"2025-09-05T14:27:57.144189","exception":false,"start_time":"2025-09-05T14:27:57.125820","status":"completed"},"tags":[]},"outputs":[],"source":["prompt = f\"\"\"\n","This is a short plot summary of a movie:\n","\n","<<synopsis>>\n","\n","Task: analyze the summary and select CLASSES from the lists below.\n","\n","Rules (must follow all):\n","- For each aspect write EXACTLY three values, comma-separated.\n","- Use ONLY values from the provided lists. New words are forbidden.\n","- For each aspect, at least one value must be a real class (not \"not_specified\").\n","- If only one or two values fit, pad the remaining slots with \"not_specified\".\n","- Output EXACTLY 15 lines in the ORDER shown below (one line per aspect).\n","- No explanations, no extra lines, no trailing text.\n","\n","Answer strictly in the format:\n","aspect_name: class_1, class_2, class_3\n","\n","Lists of aspects and classes:\n","\n","genre: drama, comedy, thriller, horror, action, adventure, crime, romance, sci_fi, fantasy, war, historical, biography, mystery, western, sports, musical, family, animation, documentary, satire, superhero, not_specified\n","\n","subgenre: noir, neo_noir, heist, courtroom, spy, detective, slasher, survival, zombie, creature_feature, folk_horror, body_horror, psychological, paranoia, cyberpunk, steampunk, post_apocalypse, dystopia, space_opera, time_travel, alternate_history, road_movie, coming_of_age, buddy, prison, disaster, political, social_drama, satire_subgenre, mockumentary, anthology, found_footage, martial_arts, revenge, gangster, whodunit, not_specified\n","\n","tone: dark, bleak, gritty, tense, suspenseful, tragic, serious, bittersweet, hopeful, uplifting, light, whimsical, romantic, ironic, satirical, epic, intimate, melancholic, not_specified\n","\n","setting_place: city, suburb, village, countryside, island, desert, mountains, forest, jungle, arctic, ocean, school, university, hospital, prison, court, warzone, battlefield, military_base, space, spaceship, space_station, future_city, fantasy_world, parallel_world, post_apocalypse_wasteland, underworld_criminal, corporate_office, small_town, road, house, apartment, monastery, castle, mine, not_specified\n","\n","setting_time: antiquity, medieval, renaissance, xviii_century, xix_century, early_xx, mid_xx, late_xx, present, near_future, far_future, timeless, alternate_history, not_specified\n","\n","protagonist_archetype: everyman, teenager, child, family, detective, cop, private_eye, criminal, hitman, soldier, veteran, resistance_member, scientist, engineer, doctor, teacher, artist, athlete, journalist, lawyer, leader, monarch, politician, spy, hacker, survivor, antihero, superhero, monster_protagonist, outsider, immigrant, pilgrim, prisoner, not_specified\n","\n","antagonist_type: person, rival, serial_killer, criminal_org, corrupt_cop, corporation, system, society, government, cult, nature, disease, poverty, addiction, inner_demon, fate, supernatural, ghost, demon, monster, alien, ai, virus, war, environment, not_specified\n","\n","relationship_dynamics: love, friendship, rivalry, family, mentorship, team, found_family, betrayal, enemies_to_lovers, love_triangle, loner, mentor_student, siblings, parent_child, not_specified\n","\n","core_goal: survive, escape, protect, rescue, find, uncover_secret, solve_crime, prove_innocence, revenge, win, save_world, stop_villain, build_relationship, self_discovery, rise_to_power, restore_order, heist_score, expose_conspiracy, not_specified\n","\n","inciting_incident: murder, kidnapping, robbery, disaster, accident, betrayal_hook, diary, prophecy, inheritance, new_job, arrival_of_stranger, war_outbreak, outbreak_virus, aliens_arrival, time_anomaly, parallel_worlds, conspiracy_revealed, magic_awakens, ai_malfunction, forbidden_love, not_specified\n","\n","themes: love, friendship, family, betrayal, loyalty, freedom, justice, power, corruption, greed, guilt, forgiveness, redemption, survival, identity, coming_of_age, class, race, immigration, war, revolution, oppression, resistance, faith, doubt, science, technology, ecology, capitalism, art, fame, myth, destiny, madness, memory, trauma, grief, hope, not_specified\n","\n","scale: personal, local, national, global, cosmic, not_specified\n","\n","narrative_structure: linear, non_linear, multi_timeline, frame_story, real_time, unreliable_narrator, anthology_structure, puzzle_plot, chaptered, not_specified\n","\n","pacing: slow_burn, measured, brisk, breakneck, not_specified\n","\n","ending_tone: happy, tragic, bittersweet, ambiguous, twist, not_specified\n","\n","Now, your answer:\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"id":"14e1e93b","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:27:57.160206Z","iopub.status.busy":"2025-09-05T14:27:57.160006Z","iopub.status.idle":"2025-09-05T14:27:57.743804Z","shell.execute_reply":"2025-09-05T14:27:57.743029Z"},"id":"14e1e93b","papermill":{"duration":0.593347,"end_time":"2025-09-05T14:27:57.745301","exception":false,"start_time":"2025-09-05T14:27:57.151954","status":"completed"},"tags":[]},"outputs":[],"source":["hf_token = ''\n","\n","from huggingface_hub import login\n","import os\n","\n","\n","login(token=hf_token)"]},{"cell_type":"code","execution_count":null,"id":"73da67dc","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:27:57.762521Z","iopub.status.busy":"2025-09-05T14:27:57.762337Z","iopub.status.idle":"2025-09-05T14:28:07.054198Z","shell.execute_reply":"2025-09-05T14:28:07.053608Z"},"id":"73da67dc","papermill":{"duration":9.302015,"end_time":"2025-09-05T14:28:07.055527","exception":false,"start_time":"2025-09-05T14:27:57.753512","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModel\n","import string\n","\n","# === 1. словарь допустимых классов ===\n","ASPECT_ORDER = [\n","    \"genre\",\"subgenre\",\"tone\",\"setting_place\",\"setting_time\",\n","    \"protagonist_archetype\",\"antagonist_type\",\"relationship_dynamics\",\n","    \"core_goal\",\"inciting_incident\",\"themes\",\"scale\",\n","    \"narrative_structure\",\"pacing\",\"ending_tone\"\n","]\n","\n","ASPECT_CLASSES = {\n","    \"genre\": [\"drama\",\"comedy\",\"thriller\",\"horror\",\"action\",\"adventure\",\"crime\",\"romance\",\"sci_fi\",\"fantasy\",\"war\",\"historical\",\"biography\",\"mystery\",\"western\",\"sports\",\"musical\",\"family\",\"animation\",\"documentary\",\"satire\",\"superhero\",\"not_specified\"],\n","    \"subgenre\": [\"noir\",\"neo_noir\",\"heist\",\"courtroom\",\"spy\",\"detective\",\"slasher\",\"survival\",\"zombie\",\"creature_feature\",\"folk_horror\",\"body_horror\",\"psychological\",\"paranoia\",\"cyberpunk\",\"steampunk\",\"post_apocalypse\",\"dystopia\",\"space_opera\",\"time_travel\",\"alternate_history\",\"road_movie\",\"coming_of_age\",\"buddy\",\"prison\",\"disaster\",\"political\",\"social_drama\",\"satire_subgenre\",\"mockumentary\",\"anthology\",\"found_footage\",\"martial_arts\",\"revenge\",\"gangster\",\"whodunit\",\"not_specified\"],\n","    \"tone\": [\"dark\",\"bleak\",\"gritty\",\"tense\",\"suspenseful\",\"tragic\",\"serious\",\"bittersweet\",\"hopeful\",\"uplifting\",\"light\",\"whimsical\",\"romantic\",\"ironic\",\"satirical\",\"epic\",\"intimate\",\"melancholic\",\"not_specified\"],\n","    \"setting_place\": [\"city\",\"suburb\",\"village\",\"countryside\",\"island\",\"desert\",\"mountains\",\"forest\",\"jungle\",\"arctic\",\"ocean\",\"school\",\"university\",\"hospital\",\"prison\",\"court\",\"warzone\",\"battlefield\",\"military_base\",\"space\",\"spaceship\",\"space_station\",\"future_city\",\"fantasy_world\",\"parallel_world\",\"post_apocalypse_wasteland\",\"underworld_criminal\",\"corporate_office\",\"small_town\",\"road\",\"house\",\"apartment\",\"monastery\",\"castle\",\"mine\",\"not_specified\"],\n","    \"setting_time\": [\"antiquity\",\"medieval\",\"renaissance\",\"xviii_century\",\"xix_century\",\"early_xx\",\"mid_xx\",\"late_xx\",\"present\",\"near_future\",\"far_future\",\"timeless\",\"alternate_history\",\"not_specified\"],\n","    \"protagonist_archetype\": [\"everyman\",\"teenager\",\"child\",\"family\",\"detective\",\"cop\",\"private_eye\",\"criminal\",\"hitman\",\"soldier\",\"veteran\",\"resistance_member\",\"scientist\",\"engineer\",\"doctor\",\"teacher\",\"artist\",\"athlete\",\"journalist\",\"lawyer\",\"leader\",\"monarch\",\"politician\",\"spy\",\"hacker\",\"survivor\",\"antihero\",\"superhero\",\"monster_protagonist\",\"outsider\",\"immigrant\",\"pilgrim\",\"prisoner\",\"not_specified\"],\n","    \"antagonist_type\": [\"person\",\"rival\",\"serial_killer\",\"criminal_org\",\"corrupt_cop\",\"corporation\",\"system\",\"society\",\"government\",\"cult\",\"nature\",\"disease\",\"poverty\",\"addiction\",\"inner_demon\",\"fate\",\"supernatural\",\"ghost\",\"demon\",\"monster\",\"alien\",\"ai\",\"virus\",\"war\",\"environment\",\"not_specified\"],\n","    \"relationship_dynamics\": [\"love\",\"friendship\",\"rivalry\",\"family\",\"mentorship\",\"team\",\"found_family\",\"betrayal\",\"enemies_to_lovers\",\"love_triangle\",\"loner\",\"mentor_student\",\"siblings\",\"parent_child\",\"not_specified\"],\n","    \"core_goal\": [\"survive\",\"escape\",\"protect\",\"rescue\",\"find\",\"uncover_secret\",\"solve_crime\",\"prove_innocence\",\"revenge\",\"win\",\"save_world\",\"stop_villain\",\"build_relationship\",\"self_discovery\",\"rise_to_power\",\"restore_order\",\"heist_score\",\"expose_conspiracy\",\"not_specified\"],\n","    \"inciting_incident\": [\"murder\",\"kidnapping\",\"robbery\",\"disaster\",\"accident\",\"betrayal_hook\",\"diary\",\"prophecy\",\"inheritance\",\"new_job\",\"arrival_of_stranger\",\"war_outbreak\",\"outbreak_virus\",\"aliens_arrival\",\"time_anomaly\",\"parallel_worlds\",\"conspiracy_revealed\",\"magic_awakens\",\"ai_malfunction\",\"forbidden_love\",\"not_specified\"],\n","    \"themes\": [\"love\",\"friendship\",\"family\",\"betrayal\",\"loyalty\",\"freedom\",\"justice\",\"power\",\"corruption\",\"greed\",\"guilt\",\"forgiveness\",\"redemption\",\"survival\",\"identity\",\"coming_of_age\",\"class\",\"race\",\"immigration\",\"war\",\"revolution\",\"oppression\",\"resistance\",\"faith\",\"doubt\",\"science\",\"technology\",\"ecology\",\"capitalism\",\"art\",\"fame\",\"myth\",\"destiny\",\"madness\",\"memory\",\"trauma\",\"grief\",\"hope\",\"not_specified\"],\n","    \"scale\": [\"personal\",\"local\",\"national\",\"global\",\"cosmic\",\"not_specified\"],\n","    \"narrative_structure\": [\"linear\",\"non_linear\",\"multi_timeline\",\"frame_story\",\"real_time\",\"unreliable_narrator\",\"anthology_structure\",\"puzzle_plot\",\"chaptered\",\"not_specified\"],\n","    \"pacing\": [\"slow_burn\",\"measured\",\"brisk\",\"breakneck\",\"not_specified\"],\n","    \"ending_tone\": [\"happy\",\"tragic\",\"bittersweet\",\"ambiguous\",\"twist\",\"not_specified\"],\n","}\n","\n","\n","\n","\n","def parse_one_output(text: str) -> dict[str, list[str]]:\n","    # чистка пунктуации (кроме \"_\")\n","    punct = string.punctuation.replace('_', '')\n","\n","    def drop_na(lst):\n","        return [i for i in lst if i]\n","\n","    def clean_(txt: str) -> str:\n","        return txt.translate(str.maketrans('', '', punct)).lower().strip()\n","\n","    lines = [clean_(ln) for ln in text.split(\"\\n\") if ln.strip()]\n","    dict_aspect = {asp: [\"not_specified\"]*3 for asp in ASPECT_ORDER}\n","\n","    for line in lines:\n","        parts = drop_na(line.split())\n","        if not parts:\n","            continue\n","        asp = parts[0]\n","        if asp in dict_aspect:\n","            vals = parts[1:4]\n","            # паддинг до 3\n","            while len(vals) < 3:\n","                vals.append(\"not_specified\")\n","            dict_aspect[asp] = vals[:3]\n","    return dict_aspect\n","\n","\n","# === 2. flatten словарей ===\n","def flatten_batch(dicts):\n","    tokens, aspects, spans = [], [], []\n","    cursor = 0\n","    for d in dicts:\n","        for asp in ASPECT_ORDER:\n","            vals = d[asp]  # всегда длина 3\n","            tokens.extend(vals)\n","            aspects.extend([asp]*len(vals))\n","        spans.append((cursor, cursor + len(ASPECT_ORDER)*3))\n","        cursor += len(ASPECT_ORDER)*3\n","    return tokens, aspects, spans\n","\n","# === 3. GPU encode ===\n","@torch.inference_mode()\n","def mean_pool(last_hidden_state, attention_mask):\n","    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n","    summed = (last_hidden_state * mask).sum(dim=1)\n","    counts = mask.sum(dim=1).clamp(min=1e-9)\n","    return summed / counts\n","\n","@torch.inference_mode()\n","def encode_texts(texts, tokenizer, model, device=\"cuda\", bs=64):\n","    outs = []\n","    for i in range(0, len(texts), bs):\n","        chunk = texts[i:i+bs]\n","        enc = tokenizer([t.replace(\"_\",\" \") for t in chunk],\n","                        padding=True, truncation=True,\n","                        max_length=32, return_tensors=\"pt\").to(device)\n","        out = model(**enc)\n","        if hasattr(out, \"pooler_output\") and out.pooler_output is not None:\n","            emb = out.pooler_output\n","        else:\n","            emb = mean_pool(out.last_hidden_state, enc[\"attention_mask\"])\n","        emb = F.normalize(emb, dim=-1)\n","        outs.append(emb)\n","    return torch.cat(outs, dim=0)\n","\n","# === 4. строим банк эмбеддингов для каждого аспекта ===\n","def build_bank(tokenizer, model, device=\"cuda\"):\n","    bank = {}\n","    for asp in ASPECT_ORDER:\n","        labels = ASPECT_CLASSES[asp]\n","        embs = encode_texts(labels, tokenizer, model, device=device)\n","        bank[asp] = {lbl: embs[i] for i,lbl in enumerate(labels)}\n","    return bank\n","\n","# === 5. сопоставление токенов с классами ===\n","def map_tokens(tokens, aspects, bank, tokenizer, model, device=\"cuda\"):\n","    embs = encode_texts(tokens, tokenizer, model, device=device)\n","    mapped = []\n","    for tok, asp, vec in zip(tokens, aspects, embs):\n","        # если токен уже валидный — оставляем\n","        if tok in bank[asp]:\n","            mapped.append(tok)\n","            continue\n","        # считаем косинусы\n","        cand_labels = list(bank[asp].keys())\n","        cand_embs = torch.stack([bank[asp][c] for c in cand_labels], dim=0)\n","        sims = cand_embs @ vec\n","        best = int(torch.argmax(sims).item())\n","        best_lbl = cand_labels[best]\n","        mapped.append(best_lbl)\n","    return mapped\n","\n","\n","# === 6. собираем обратно словари ===\n","def reconstruct(mapped_tokens, spans):\n","    dicts = []\n","    for start,end in spans:\n","        local = mapped_tokens[start:end]\n","        d = {}\n","        ptr = 0\n","        for asp in ASPECT_ORDER:\n","            d[asp] = local[ptr:ptr+3]\n","            ptr += 3\n","        dicts.append(d)\n","    return dicts\n","\n","# === 7. добавляем в датасет (DataFrame) ===\n","def to_dataframe(dicts, prompts=None):\n","    rows = []\n","    for i,d in enumerate(dicts):\n","        row = {}\n","        if prompts is not None:\n","            row[\"prompt\"] = prompts[i]\n","        for asp in ASPECT_ORDER:\n","            row[f\"{asp}_1\"], row[f\"{asp}_2\"], row[f\"{asp}_3\"] = d[asp]\n","        rows.append(row)\n","    cols = ([\"prompt\"] if prompts is not None else []) + [f\"{a}_{k}\" for a in ASPECT_ORDER for k in (1,2,3)]\n","    return pd.DataFrame(rows, columns=cols)\n","\n","# === 8. пайплайн ===\n","def process_batch(parsed_batch, tokenizer, model, device=\"cuda\", prompts=None):\n","    tokens, aspects, spans = flatten_batch(parsed_batch)\n","    bank = build_bank(tokenizer, model, device=device)\n","    mapped = map_tokens(tokens, aspects, bank, tokenizer, model, device=device)\n","    dicts = reconstruct(mapped, spans)\n","    # df = to_dataframe(dicts, prompts=prompts)\n","    return dicts\n"]},{"cell_type":"code","execution_count":null,"id":"85bf935e","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:28:07.072763Z","iopub.status.busy":"2025-09-05T14:28:07.072444Z","iopub.status.idle":"2025-09-05T14:30:58.744155Z","shell.execute_reply":"2025-09-05T14:30:58.743429Z"},"id":"85bf935e","papermill":{"duration":171.681798,"end_time":"2025-09-05T14:30:58.745356","exception":false,"start_time":"2025-09-05T14:28:07.063558","status":"completed"},"tags":[],"colab":{"referenced_widgets":["97f4ed455ce942d498dc6573390319f9","150a8559857a46baad33e5b8abea881a","155fd2e04b3a4f9c87049220a35d4351","290b0c6acb354e47b120cc3c6ccb9d72","78ae81f5dd594a709e3642421ddc3707","896d4a958a964929a578c0891531c652","94ed162de39749788a7057ff98bbd7f9","2ea3b1a9dd574198a730e8c92fc2c67b","69b8f2e701494e7abe38466659fbc0e3","249d7d9949be44bea41f8f7dd3fabf22","5ea70b4b812d476eacb293f2b02ec46a","e208ba162c594577a8ec53df42c1d12e"]},"outputId":"baaad370-8165-4ae2-d245-d2cdf0eab8ae"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97f4ed455ce942d498dc6573390319f9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"150a8559857a46baad33e5b8abea881a","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"155fd2e04b3a4f9c87049220a35d4351","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"290b0c6acb354e47b120cc3c6ccb9d72","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78ae81f5dd594a709e3642421ddc3707","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2025-09-05 14:28:17.347012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757082497.543984      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757082497.602636      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"896d4a958a964929a578c0891531c652","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ed162de39749788a7057ff98bbd7f9","version_major":2,"version_minor":0},"text/plain":["Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ea3b1a9dd574198a730e8c92fc2c67b","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b8f2e701494e7abe38466659fbc0e3","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"249d7d9949be44bea41f8f7dd3fabf22","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ea70b4b812d476eacb293f2b02ec46a","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e208ba162c594577a8ec53df42c1d12e","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["MistralForCausalLM(\n","  (model): MistralModel(\n","    (embed_tokens): Embedding(32000, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x MistralDecoderLayer(\n","        (self_attn): MistralAttention(\n","          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","        )\n","        (mlp): MistralMLP(\n","          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): MistralRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): MistralRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","import os, torch\n","\n","\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,expandable_segments:True,garbage_collection_threshold:0.6\"\n","torch.backends.cuda.matmul.allow_tf32 = True\n","torch.backends.cuda.enable_flash_sdp(True)\n","torch.backends.cuda.enable_mem_efficient_sdp(True)\n","torch.backends.cuda.enable_math_sdp(False)\n","\n","name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","tokenizer_mistral = AutoTokenizer.from_pretrained(name)\n","if tokenizer_mistral.pad_token_id is None:\n","    tokenizer_mistral.pad_token_id = tokenizer_mistral.eos_token_id\n","\n","mistral_model = AutoModelForCausalLM.from_pretrained(\n","    name,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",                       # model-parallel по всем GPU\n","    low_cpu_mem_usage=True,\n","\n","    # max_memory={\"cuda:0\":\"15GiB\",\"cuda:1\":\"15GiB\"},  # опционально\n",")\n","mistral_model.generation_config.pad_token_id = tokenizer_mistral.pad_token_id\n","mistral_model.eval()"]},{"cell_type":"code","execution_count":null,"id":"e7103c9e","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:30:58.764519Z","iopub.status.busy":"2025-09-05T14:30:58.763594Z","iopub.status.idle":"2025-09-05T14:31:05.319117Z","shell.execute_reply":"2025-09-05T14:31:05.318495Z"},"id":"e7103c9e","papermill":{"duration":6.565831,"end_time":"2025-09-05T14:31:05.320247","exception":false,"start_time":"2025-09-05T14:30:58.754416","status":"completed"},"tags":[],"colab":{"referenced_widgets":["055fdd23e5af49208692e56709aa6ce3","25b7e8849643442587ee8642d7fde81c","1aa68b5bb7234e48a94e589c8a41b803","1a6edb37880344258e412265f7af479c","7d8a495e01f44e07a1abf133c4843fe2","64606ddb8f584c5f908ee4da5fe66207"]},"outputId":"5b72b53b-a565-4816-af7d-b9f66e5673f0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"055fdd23e5af49208692e56709aa6ce3","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25b7e8849643442587ee8642d7fde81c","version_major":2,"version_minor":0},"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1aa68b5bb7234e48a94e589c8a41b803","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a6edb37880344258e412265f7af479c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d8a495e01f44e07a1abf133c4843fe2","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64606ddb8f584c5f908ee4da5fe66207","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["device = \"cuda:1\"\n","MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # можно заменить на bge, e5 и т.д.\n","tok_vect = AutoTokenizer.from_pretrained(MODEL)\n","model_vect = AutoModel.from_pretrained(MODEL).to(device).eval()"]},{"cell_type":"code","execution_count":null,"id":"fd65cbc3","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:31:05.339750Z","iopub.status.busy":"2025-09-05T14:31:05.339524Z","iopub.status.idle":"2025-09-05T14:31:07.282772Z","shell.execute_reply":"2025-09-05T14:31:07.282188Z"},"id":"fd65cbc3","papermill":{"duration":1.954272,"end_time":"2025-09-05T14:31:07.284264","exception":false,"start_time":"2025-09-05T14:31:05.329992","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","df = pd.read_parquet(\"/kaggle/input/promts-for-sematinc/prompts.parquet\")\n","\n","def create_prompt(syn, base_prompt=prompt):\n","    mask = '<<synopsis>>'\n","    return base_prompt.replace(mask, syn)\n","\n","df = df[['plot']].drop_duplicates()\n","df['prompt'] = df['plot'].apply(create_prompt)\n","df['desc'] = ''\n","\n","df = df.sort_values(by=\"prompt\", key=lambda col: col.str.len())"]},{"cell_type":"code","execution_count":null,"id":"5c6696f3","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:31:07.304208Z","iopub.status.busy":"2025-09-05T14:31:07.303717Z","iopub.status.idle":"2025-09-05T14:31:07.307437Z","shell.execute_reply":"2025-09-05T14:31:07.306723Z"},"papermill":{"duration":0.01459,"end_time":"2025-09-05T14:31:07.308587","exception":false,"start_time":"2025-09-05T14:31:07.293997","status":"completed"},"tags":[],"id":"5c6696f3"},"outputs":[],"source":["df = df.iloc[6144:]"]},{"cell_type":"code","execution_count":null,"id":"27bfbaa3","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:31:07.327899Z","iopub.status.busy":"2025-09-05T14:31:07.327464Z","iopub.status.idle":"2025-09-05T14:31:07.331463Z","shell.execute_reply":"2025-09-05T14:31:07.330772Z"},"papermill":{"duration":0.014711,"end_time":"2025-09-05T14:31:07.332576","exception":false,"start_time":"2025-09-05T14:31:07.317865","status":"completed"},"tags":[],"id":"27bfbaa3"},"outputs":[],"source":["def dict_to_text(d: dict) -> str:\n","    lines = []\n","    for k, v in d.items():\n","        # v гарантированно список из 3х элементов\n","        values = \", \".join(v)\n","        lines.append(f\"{k}: {values}\")\n","    return \"\\n\".join(lines)"]},{"cell_type":"code","execution_count":null,"id":"1dafb433","metadata":{"execution":{"iopub.execute_input":"2025-09-05T14:31:07.351677Z","iopub.status.busy":"2025-09-05T14:31:07.351321Z","iopub.status.idle":"2025-09-05T16:15:53.784198Z","shell.execute_reply":"2025-09-05T16:15:53.783470Z"},"id":"1dafb433","outputId":"f9fffa64-d263-4437-9e10-14858c7d6321","papermill":{"duration":6286.44393,"end_time":"2025-09-05T16:15:53.785650","exception":false,"start_time":"2025-09-05T14:31:07.341720","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]}],"source":["\n","saved_per_batch = 16\n","batch_size = 8\n","n = 0\n","for i in range(0, len(df), batch_size):\n","    batch = df.iloc[i:i+batch_size]\n","    prompts = batch['prompt'].tolist()\n","\n","    inputs = tokenizer_mistral(prompts, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n","\n","    with torch.inference_mode():\n","        outputs = mistral_model.generate(\n","            **inputs,\n","            max_new_tokens=180,\n","            temperature=0.0,\n","            do_sample=False\n","        )\n","\n","    decoded = []\n","    input_len = inputs[\"input_ids\"].shape[1]\n","    for output in outputs:\n","        text = tokenizer_mistral.decode(output[input_len:], skip_special_tokens=True)\n","        decoded.append(text)\n","\n","    # парсим \"грязные\" выходы\n","    parsed_batch = [parse_one_output(txt) for txt in decoded]\n","    # обрабатываем через твой пайплайн\n","    descriptions = process_batch(parsed_batch, tok_vect, model_vect, device=device)\n","    descriptions = [dict_to_text(d) for d in descriptions]\n","    # сохраняем обратно\n","    df.loc[batch.index, 'desc'] = descriptions\n","\n","    # периодическое сохранение\n","    if (i // batch_size + 1) % saved_per_batch == 0:\n","        df.to_parquet(\"plot_prompt_desc.parquet\", index=False)\n","\n","df.to_parquet(\"plot_prompt_desc_final.parquet\", index=False)"]},{"cell_type":"code","execution_count":null,"id":"113cdf71","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:15:53.813697Z","iopub.status.busy":"2025-09-05T16:15:53.813464Z","iopub.status.idle":"2025-09-05T16:15:53.816771Z","shell.execute_reply":"2025-09-05T16:15:53.816269Z"},"id":"113cdf71","papermill":{"duration":0.018635,"end_time":"2025-09-05T16:15:53.817992","exception":false,"start_time":"2025-09-05T16:15:53.799357","status":"completed"},"tags":[]},"outputs":[],"source":["# def count_not_specified(original_dicts, mapped_dicts):\n","#     \"\"\"\n","#     original_dicts: список словарей (от твоего парсера, ещё до замены)\n","#     mapped_dicts:   список словарей (после process_batch)\n","#     возвращает список кортежей (orig_count, mapped_count) по каждому тексту\n","#     \"\"\"\n","#     results = []\n","#     for orig, mapped in zip(original_dicts, mapped_dicts):\n","#         orig_count = sum(v == \"not_specified\" for vals in orig.values() for v in vals)\n","#         mapped_count = sum(v == \"not_specified\" for vals in mapped.values() for v in vals)\n","#         results.append((orig_count, mapped_count))\n","#     return results\n","# # допустим, у тебя есть:\n","# # parsed_batch = [parse_one_output_my(txt) for txt in raw_outputs]\n","# # dicts, df = process_batch(parsed_batch, tok, mdl, device=\"cuda\")\n","\n","# stats = count_not_specified(parsed_batch, dicts)\n","\n","# for i, (o, m) in enumerate(stats, 1):\n","#     print(f\"Текст {i}: not_specified было {o}, стало {m}\")\n"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":7844142,"sourceId":12900406,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":6484.730422,"end_time":"2025-09-05T16:15:57.834048","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-05T14:27:53.103626","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}